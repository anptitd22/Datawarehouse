{"timestamp":"2025-06-21T09:08:27.649197","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-06-21T09:08:27.650175","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-06-21T09:08:28.924685Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-21T09:08:28.925865Z","level":"info","event":" Previous state of the Task instance: queued","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-21T09:08:28.926454Z","level":"info","event":"Current task name:dim_order_group.producer_kafka","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-21T09:08:28.926857Z","level":"info","event":"Dag name:etl_pipeline","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-21T09:08:28.927207Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:31.199610Z","level":"error","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:31.372559Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:31.373894Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:31.383168Z","level":"error","event":"org.postgresql#postgresql added as a dependency","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:31.388276Z","level":"error","event":"org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:31.393257Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-e85650d8-53ec-4d9f-a7f2-bdacfc3105cd;1.0","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:31.394521Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:31.632767Z","level":"error","event":"\tfound org.postgresql#postgresql;42.7.1 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:31.665947Z","level":"error","event":"\tfound org.checkerframework#checker-qual;3.41.0 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:31.778163Z","level":"error","event":"\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.3.0 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:31.861188Z","level":"error","event":"\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.0 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:31.900981Z","level":"error","event":"\tfound org.apache.kafka#kafka-clients;2.8.1 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:31.946860Z","level":"error","event":"\tfound org.lz4#lz4-java;1.8.0 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:31.995040Z","level":"error","event":"\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.029831Z","level":"error","event":"\tfound org.slf4j#slf4j-api;1.7.32 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.087901Z","level":"error","event":"\tfound org.apache.hadoop#hadoop-client-runtime;3.3.2 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.122918Z","level":"error","event":"\tfound org.spark-project.spark#unused;1.0.0 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.185950Z","level":"error","event":"\tfound org.apache.hadoop#hadoop-client-api;3.3.2 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.248379Z","level":"error","event":"\tfound commons-logging#commons-logging;1.1.3 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.286227Z","level":"error","event":"\tfound com.google.code.findbugs#jsr305;3.0.0 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.330606Z","level":"error","event":"\tfound org.apache.commons#commons-pool2;2.11.1 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.438542Z","level":"error","event":":: resolution report :: resolve 975ms :: artifacts dl 78ms","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.442609Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.443528Z","level":"error","event":"\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.443989Z","level":"error","event":"\tcommons-logging#commons-logging;1.1.3 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.444488Z","level":"error","event":"\torg.apache.commons#commons-pool2;2.11.1 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.444813Z","level":"error","event":"\torg.apache.hadoop#hadoop-client-api;3.3.2 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.445432Z","level":"error","event":"\torg.apache.hadoop#hadoop-client-runtime;3.3.2 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.445765Z","level":"error","event":"\torg.apache.kafka#kafka-clients;2.8.1 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.446209Z","level":"error","event":"\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.3.0 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.446466Z","level":"error","event":"\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.0 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.446708Z","level":"error","event":"\torg.checkerframework#checker-qual;3.41.0 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.446995Z","level":"error","event":"\torg.lz4#lz4-java;1.8.0 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.447264Z","level":"error","event":"\torg.postgresql#postgresql;42.7.1 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.447496Z","level":"error","event":"\torg.slf4j#slf4j-api;1.7.32 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.447744Z","level":"error","event":"\torg.spark-project.spark#unused;1.0.0 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.448490Z","level":"error","event":"\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.448942Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.449205Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.449488Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.449770Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.449996Z","level":"error","event":"\t|      default     |   14  |   0   |   0   |   0   ||   14  |   0   |","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.450201Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.459266Z","level":"error","event":":: retrieving :: org.apache.spark#spark-submit-parent-e85650d8-53ec-4d9f-a7f2-bdacfc3105cd","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.460422Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.477123Z","level":"error","event":"\t0 artifacts copied, 14 already retrieved (0kB/17ms)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:32.984533Z","level":"error","event":"25/06/21 09:08:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:33.386355Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:33.387892Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:33.388584Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:36.223570Z","level":"error","event":"25/06/21 09:08:36 WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting port 4051.","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:08:58.075748","level":"info","event":"Thử lần 1/5 kiểm tra topic 'dim_order'...","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:09:03.268384","level":"warning","event":"⚠Lỗi khi kiểm tra/tạo topic 'dim_order': KafkaError{code=_TRANSPORT,val=-195,str=\"Failed to get metadata: Local: Broker transport failure\"}","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:09:03.376779","level":"info","event":"Đợi 3 giây rồi thử lại...","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:09:08.506815","level":"info","event":"Thử lần 2/5 kiểm tra topic 'dim_order'...","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:09:13.743926","level":"warning","event":"⚠Lỗi khi kiểm tra/tạo topic 'dim_order': KafkaError{code=_TRANSPORT,val=-195,str=\"Failed to get metadata: Local: Broker transport failure\"}","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:09:13.748365","level":"info","event":"Đợi 3 giây rồi thử lại...","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:09:14.938621Z","level":"error","event":"%3|1750496948.508|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Temporary failure in name resolution (after 10418ms in state CONNECT)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:09:14.939204Z","level":"error","event":"%3|1750496948.508|FAIL|rdkafka#producer-2| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Failed to resolve 'kafka:9092': Temporary failure in name resolution (after 10414ms in state CONNECT)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:09:16.026527","level":"info","event":"Thử lần 3/5 kiểm tra topic 'dim_order'...","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:09:16.040198","level":"info","event":"Đang tạo topic 'dim_order' với 5 partitions...","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:09:17.526950","level":"info","event":"Đã tạo topic: dim_order","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:09:17.533402","level":"info","event":"extract_dim_order","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:11:37.214318","level":"info","event":"transform dim_order","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:11:42.411150","level":"info","event":"Extract và transform dim_order thành công","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:13:00.204047Z","level":"error","event":"\r[Stage 0:>                                                          (0 + 0) / 1]\r\r[Stage 0:>                                                          (0 + 1) / 1]\r\r                                                                                \r\r[Stage 1:>                                                          (0 + 1) / 1]\r25/06/21 09:12:57 WARN TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1) (172.19.0.9 executor 2): org.postgresql.util.PSQLException: The connection attempt failed.","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.204656Z","level":"error","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.205028Z","level":"error","event":"\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.205437Z","level":"error","event":"\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.205926Z","level":"error","event":"\tat org.postgresql.Driver.makeConnection(Driver.java:444)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.206257Z","level":"error","event":"\tat org.postgresql.Driver.connect(Driver.java:297)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.206614Z","level":"error","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.207696Z","level":"error","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.207984Z","level":"error","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.208313Z","level":"error","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.208676Z","level":"error","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:260)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.208980Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.209274Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.209561Z","level":"error","event":"\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.209854Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.210162Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.210444Z","level":"error","event":"\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.210717Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.210958Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.211236Z","level":"error","event":"\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:107)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.211454Z","level":"error","event":"\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.211700Z","level":"error","event":"\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.212177Z","level":"error","event":"\tat org.apache.spark.scheduler.Task.run(Task.scala:147)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.212451Z","level":"error","event":"\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.212810Z","level":"error","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.213228Z","level":"error","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.213514Z","level":"error","event":"\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.213819Z","level":"error","event":"\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.214134Z","level":"error","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.214418Z","level":"error","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.214682Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.214982Z","level":"error","event":"Caused by: java.net.SocketTimeoutException","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.215276Z","level":"error","event":"\tat java.base/java.net.SocksSocketImpl.remainingMillis(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.215580Z","level":"error","event":"\tat java.base/java.net.SocksSocketImpl.connect(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.215801Z","level":"error","event":"\tat java.base/java.net.Socket.connect(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.216060Z","level":"error","event":"\tat org.postgresql.core.PGStream.createSocket(PGStream.java:243)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.216302Z","level":"error","event":"\tat org.postgresql.core.PGStream.<init>(PGStream.java:98)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.216569Z","level":"error","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.216897Z","level":"error","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.217171Z","level":"error","event":"\t... 29 more","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:00.217469Z","level":"error","event":"","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:12:59.663189","level":"info","event":"Tổng số bản ghi cần gửi: 20","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:13:02.078364","level":"info","event":"Batch 1: 20 bản ghi. Đang gửi lên Kafka...","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:13:11.285354","level":"info","event":"Delivered to dim_order [0] at offset 0","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.288287","level":"info","event":"Delivered to dim_order [0] at offset 1","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.288516","level":"info","event":"Delivered to dim_order [0] at offset 2","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.288618","level":"info","event":"Delivered to dim_order [0] at offset 3","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.288686","level":"info","event":"Delivered to dim_order [0] at offset 4","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.288747","level":"info","event":"Delivered to dim_order [0] at offset 5","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.288806","level":"info","event":"Delivered to dim_order [0] at offset 6","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.288872","level":"info","event":"Delivered to dim_order [1] at offset 0","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.288946","level":"info","event":"Delivered to dim_order [2] at offset 0","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.289072","level":"info","event":"Delivered to dim_order [2] at offset 1","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.289162","level":"info","event":"Delivered to dim_order [2] at offset 2","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.289224","level":"info","event":"Delivered to dim_order [3] at offset 0","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.289276","level":"info","event":"Delivered to dim_order [3] at offset 1","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.289330","level":"info","event":"Delivered to dim_order [3] at offset 2","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.289385","level":"info","event":"Delivered to dim_order [3] at offset 3","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.289440","level":"info","event":"Delivered to dim_order [4] at offset 0","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.289495","level":"info","event":"Delivered to dim_order [4] at offset 1","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.289553","level":"info","event":"Delivered to dim_order [4] at offset 2","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.289659","level":"info","event":"Delivered to dim_order [4] at offset 3","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:11.289732","level":"info","event":"Delivered to dim_order [4] at offset 4","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:14.983638","level":"info","event":"extract_dim_order","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:13:19.960947","level":"info","event":"transform dim_order","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:13:20.025651","level":"info","event":"Extract và transform dim_order thành công","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:13:21.078932","level":"info","event":"Tổng số bản ghi cần gửi: 20","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:13:21.621905","level":"info","event":"Batch 2: 20 bản ghi. Đang gửi lên Kafka...","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:13:22.128371","level":"info","event":"Delivered to dim_order [4] at offset 5","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.131395","level":"info","event":"Delivered to dim_order [4] at offset 6","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.131586","level":"info","event":"Delivered to dim_order [4] at offset 7","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.131644","level":"info","event":"Delivered to dim_order [4] at offset 8","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.131803","level":"info","event":"Delivered to dim_order [4] at offset 9","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.131882","level":"info","event":"Delivered to dim_order [4] at offset 10","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.131972","level":"info","event":"Delivered to dim_order [0] at offset 7","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.132041","level":"info","event":"Delivered to dim_order [0] at offset 8","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.132102","level":"info","event":"Delivered to dim_order [0] at offset 9","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.132167","level":"info","event":"Delivered to dim_order [0] at offset 10","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.132239","level":"info","event":"Delivered to dim_order [1] at offset 1","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.132304","level":"info","event":"Delivered to dim_order [1] at offset 2","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.132366","level":"info","event":"Delivered to dim_order [1] at offset 3","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.134740","level":"info","event":"Delivered to dim_order [2] at offset 3","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.134940","level":"info","event":"Delivered to dim_order [2] at offset 4","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.135035","level":"info","event":"Delivered to dim_order [2] at offset 5","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.136846","level":"info","event":"Delivered to dim_order [3] at offset 4","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.136986","level":"info","event":"Delivered to dim_order [3] at offset 5","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.137055","level":"info","event":"Delivered to dim_order [3] at offset 6","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:22.137122","level":"info","event":"Delivered to dim_order [3] at offset 7","logger":"kafka.build_kafka"}
{"timestamp":"2025-06-21T09:13:24.200906","level":"info","event":"extract_dim_order","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:13:26.286879","level":"info","event":"transform dim_order","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:13:26.543722","level":"info","event":"Extract và transform dim_order thành công","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:13:41.674844","level":"info","event":"Tổng số bản ghi cần gửi: 20","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:13:42.837305Z","level":"error","event":"\r[Stage 3:>                                                          (0 + 1) / 1]\r\r                                                                                \r\r[Stage 4:>                                                          (0 + 1) / 1]\r\r                                                                                \r\r[Stage 7:>                                                          (0 + 1) / 1]\r\r[Stage 8:>                                                          (0 + 1) / 1]\r\r                                                                                \r\r[Stage 19:>                                                         (0 + 1) / 1]\r\r                                                                                \r\r[Stage 23:>                                                         (0 + 1) / 1]\r25/06/21 09:13:40 WARN TaskSetManager: Lost task 0.0 in stage 23.0 (TID 18) (172.19.0.8 executor 3): org.postgresql.util.PSQLException: The connection attempt failed.","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.837794Z","level":"error","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.838218Z","level":"error","event":"\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.838469Z","level":"error","event":"\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.838830Z","level":"error","event":"\tat org.postgresql.Driver.makeConnection(Driver.java:444)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.839132Z","level":"error","event":"\tat org.postgresql.Driver.connect(Driver.java:297)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.839626Z","level":"error","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.840042Z","level":"error","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.840425Z","level":"error","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.840797Z","level":"error","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.841154Z","level":"error","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:260)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.841650Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.841994Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.842272Z","level":"error","event":"\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.842564Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.842829Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.843074Z","level":"error","event":"\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.843335Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.843614Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.843830Z","level":"error","event":"\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:107)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.844061Z","level":"error","event":"\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.844384Z","level":"error","event":"\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.844609Z","level":"error","event":"\tat org.apache.spark.scheduler.Task.run(Task.scala:147)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.844805Z","level":"error","event":"\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.844997Z","level":"error","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.845269Z","level":"error","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.845543Z","level":"error","event":"\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.845794Z","level":"error","event":"\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.845993Z","level":"error","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.846153Z","level":"error","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.846332Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.846558Z","level":"error","event":"Caused by: java.net.UnknownHostException: postgres_container","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.846746Z","level":"error","event":"\tat java.base/sun.nio.ch.NioSocketImpl.connect(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.847008Z","level":"error","event":"\tat java.base/java.net.SocksSocketImpl.connect(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.847343Z","level":"error","event":"\tat java.base/java.net.Socket.connect(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.847677Z","level":"error","event":"\tat org.postgresql.core.PGStream.createSocket(PGStream.java:243)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.848011Z","level":"error","event":"\tat org.postgresql.core.PGStream.<init>(PGStream.java:98)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.848433Z","level":"error","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.848728Z","level":"error","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.849004Z","level":"error","event":"\t... 29 more","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.849288Z","level":"error","event":"","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.849616Z","level":"error","event":"\r                                                                                \r25/06/21 09:13:41 WARN TaskSetManager: Lost task 0.0 in stage 26.0 (TID 22) (172.19.0.8 executor 3): org.postgresql.util.PSQLException: The connection attempt failed.","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.849936Z","level":"error","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.850232Z","level":"error","event":"\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.850549Z","level":"error","event":"\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.850859Z","level":"error","event":"\tat org.postgresql.Driver.makeConnection(Driver.java:444)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.851153Z","level":"error","event":"\tat org.postgresql.Driver.connect(Driver.java:297)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.851365Z","level":"error","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.851606Z","level":"error","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.183333","level":"error","event":"Lỗi trong quá trình gửi Kafka: An error occurred while calling o99.count.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 26.0 failed 4 times, most recent failure: Lost task 0.3 in stage 26.0 (TID 25) (172.19.0.8 executor 3): org.postgresql.util.PSQLException: The connection attempt failed.\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)\n\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)\n\tat org.postgresql.Driver.makeConnection(Driver.java:444)\n\tat org.postgresql.Driver.connect(Driver.java:297)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)\n\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)\n\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:260)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:107)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n\tat java.base/java.lang.Thread.run(Unknown Source)\nCaused by: java.net.UnknownHostException: postgres_container\n\tat java.base/sun.nio.ch.NioSocketImpl.connect(Unknown Source)\n\tat java.base/java.net.SocksSocketImpl.connect(Unknown Source)\n\tat java.base/java.net.Socket.connect(Unknown Source)\n\tat org.postgresql.core.PGStream.createSocket(PGStream.java:243)\n\tat org.postgresql.core.PGStream.<init>(PGStream.java:98)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)\n\t... 29 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n\tat scala.collection.immutable.List.foreach(List.scala:334)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n\tat scala.Option.foreach(Option.scala:437)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\nCaused by: org.postgresql.util.PSQLException: The connection attempt failed.\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)\n\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)\n\tat org.postgresql.Driver.makeConnection(Driver.java:444)\n\tat org.postgresql.Driver.connect(Driver.java:297)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)\n\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)\n\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:260)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:107)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n\tat java.base/java.lang.Thread.run(Unknown Source)\nCaused by: java.net.UnknownHostException: postgres_container\n\tat java.base/sun.nio.ch.NioSocketImpl.connect(Unknown Source)\n\tat java.base/java.net.SocksSocketImpl.connect(Unknown Source)\n\tat java.base/java.net.Socket.connect(Unknown Source)\n\tat org.postgresql.core.PGStream.createSocket(PGStream.java:243)\n\tat org.postgresql.core.PGStream.<init>(PGStream.java:98)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)\n\t... 29 more\n","logger":"dags.etl_dim_order"}
{"timestamp":"2025-06-21T09:13:42.875803Z","level":"error","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.876223Z","level":"error","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.876606Z","level":"error","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:260)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.877148Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.877548Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.877901Z","level":"error","event":"\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.878315Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.879811Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.883305Z","level":"error","event":"\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.883813Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.884085Z","level":"error","event":"\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.884354Z","level":"error","event":"\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:107)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.884650Z","level":"error","event":"\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.885150Z","level":"error","event":"\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.885450Z","level":"error","event":"\tat org.apache.spark.scheduler.Task.run(Task.scala:147)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.885731Z","level":"error","event":"\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.885992Z","level":"error","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.886246Z","level":"error","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.886547Z","level":"error","event":"\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.886821Z","level":"error","event":"\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.887107Z","level":"error","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.887382Z","level":"error","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.887636Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.887880Z","level":"error","event":"Caused by: java.net.UnknownHostException: postgres_container","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.888086Z","level":"error","event":"\tat java.base/sun.nio.ch.NioSocketImpl.connect(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.888284Z","level":"error","event":"\tat java.base/java.net.SocksSocketImpl.connect(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.888484Z","level":"error","event":"\tat java.base/java.net.Socket.connect(Unknown Source)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.888719Z","level":"error","event":"\tat org.postgresql.core.PGStream.createSocket(PGStream.java:243)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.888929Z","level":"error","event":"\tat org.postgresql.core.PGStream.<init>(PGStream.java:98)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.889149Z","level":"error","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.889343Z","level":"error","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.889553Z","level":"error","event":"\t... 29 more","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.889731Z","level":"error","event":"","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:42.889997Z","level":"error","event":"25/06/21 09:13:41 ERROR TaskSetManager: Task 0 in stage 26.0 failed 4 times; aborting job","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-21T09:13:43.312469","level":"info","event":"Done. Returned value was: None","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
{"timestamp":"2025-06-21T09:13:43.483397Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-21T09:13:43.483942Z","level":"info","event":" Previous state of the Task instance: running","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-21T09:13:43.485778Z","level":"info","event":"Task operator:<Task(PythonOperator): dim_order_group.producer_kafka>","chan":"stdout","logger":"task"}
