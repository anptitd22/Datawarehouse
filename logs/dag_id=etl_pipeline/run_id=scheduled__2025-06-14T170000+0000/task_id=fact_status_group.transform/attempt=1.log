{"timestamp":"2025-06-14T17:00:13.461716","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-06-14T17:00:13.462543","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-06-14T17:00:13.674056Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-14T17:00:13.674729Z","level":"info","event":" Previous state of the Task instance: queued","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-14T17:00:13.675052Z","level":"info","event":"Current task name:fact_status_group.transform","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-14T17:00:13.675358Z","level":"info","event":"Dag name:etl_pipeline","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-14T17:00:13.650997","level":"info","event":"Secrets backends loaded for worker","count":1,"backend_classes":["EnvironmentVariablesBackend"],"logger":"supervisor"}
{"timestamp":"2025-06-14T17:00:13.675128","level":"info","event":"Connection Retrieved 'postgres_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-06-14T17:00:13.689603","level":"warning","event":"/opt/airflow/dags/etl_fact_status.py:24: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  df = pd.read_sql(\"\"\"\n","logger":"py.warnings"}
{"timestamp":"2025-06-14T17:00:13.725119","level":"info","event":"Secrets backends loaded for worker","count":1,"backend_classes":["EnvironmentVariablesBackend"],"logger":"supervisor"}
{"timestamp":"2025-06-14T17:00:13.734082","level":"info","event":"Connection Retrieved 'sqlserver_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-06-14T17:00:13.763506","level":"warning","event":"/opt/airflow/dags/etl_fact_status.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  date_df = pd.read_sql(\"SELECT date, date_key FROM dim_date\", sql_conn)\n","logger":"py.warnings"}
{"timestamp":"2025-06-14T17:00:13.770602","level":"warning","event":"/opt/airflow/dags/etl_fact_status.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  order_df = pd.read_sql(\"SELECT order_id, order_key FROM dim_order\", sql_conn)\n","logger":"py.warnings"}
{"timestamp":"2025-06-14T17:00:13.813703","level":"info","event":"Done. Returned value was:       order_key  date_key  ...  delivery_percentage  cancel_percentage\n0          5990      2646  ...                100.0                0.0\n1          6114      2077  ...                100.0                0.0\n2          3923      2460  ...                100.0                0.0\n3          5787      2411  ...                100.0                0.0\n4          4350      2497  ...                100.0                0.0\n...         ...       ...  ...                  ...                ...\n3726       5789      2433  ...                100.0                0.0\n3727       6424      2618  ...                100.0                0.0\n3728       5007      2541  ...                100.0                0.0\n3729       5280      2332  ...                100.0                0.0\n3730       5791      2187  ...                100.0                0.0\n\n[3731 rows x 6 columns]","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
{"timestamp":"2025-06-14T17:00:13.814113","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('01976f62-43f0-7af1-9b71-c258ef71290f'), task_id='fact_status_group.transform', dag_id='etl_pipeline', run_id='scheduled__2025-06-14T17:00:00+00:00', try_number=1, map_index=-1, hostname='b2bda57f10c1', context_carrier={}, task=<Task(PythonOperator): fact_status_group.transform>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=1, start_date=datetime.datetime(2025, 6, 14, 17, 0, 12, 872468, tzinfo=TzInfo(UTC)), end_date=None, is_mapped=False)","logger":"task"}
{"timestamp":"2025-06-14T17:00:13.829655Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-14T17:00:13.830277Z","level":"info","event":" Previous state of the Task instance: running","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-14T17:00:13.830649Z","level":"info","event":"Task operator:<Task(PythonOperator): fact_status_group.transform>","chan":"stdout","logger":"task"}
