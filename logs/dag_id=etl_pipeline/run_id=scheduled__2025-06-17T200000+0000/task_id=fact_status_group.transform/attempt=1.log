{"timestamp":"2025-06-17T20:00:36.420133","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-06-17T20:00:36.420872","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-06-17T20:00:37.046726Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-17T20:00:37.047446Z","level":"info","event":" Previous state of the Task instance: queued","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-17T20:00:37.047871Z","level":"info","event":"Current task name:fact_status_group.transform","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-17T20:00:37.048242Z","level":"info","event":"Dag name:etl_pipeline","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-17T20:00:37.022942","level":"info","event":"Secrets backends loaded for worker","count":1,"backend_classes":["EnvironmentVariablesBackend"],"logger":"supervisor"}
{"timestamp":"2025-06-17T20:00:37.047903","level":"info","event":"Connection Retrieved 'postgres_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-06-17T20:00:37.061919","level":"warning","event":"/opt/airflow/dags/etl_fact_status.py:24: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  df = pd.read_sql(\"\"\"\n","logger":"py.warnings"}
{"timestamp":"2025-06-17T20:00:37.103168","level":"info","event":"Secrets backends loaded for worker","count":1,"backend_classes":["EnvironmentVariablesBackend"],"logger":"supervisor"}
{"timestamp":"2025-06-17T20:00:37.113273","level":"info","event":"Connection Retrieved 'sqlserver_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-06-17T20:00:37.234827","level":"warning","event":"/opt/airflow/dags/etl_fact_status.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  date_df = pd.read_sql(\"SELECT date, date_key FROM dim_date\", sql_conn)\n","logger":"py.warnings"}
{"timestamp":"2025-06-17T20:00:37.259554","level":"warning","event":"/opt/airflow/dags/etl_fact_status.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  order_df = pd.read_sql(\"SELECT order_id, order_key FROM dim_order\", sql_conn)\n","logger":"py.warnings"}
{"timestamp":"2025-06-17T20:00:37.326023","level":"info","event":"Done. Returned value was:       order_key  date_key  ...  delivery_percentage  cancel_percentage\n0          9721      4107  ...                100.0                0.0\n1          9845      3538  ...                100.0                0.0\n2          7654      3921  ...                100.0                0.0\n3          9518      3872  ...                100.0                0.0\n4          8081      3958  ...                100.0                0.0\n...         ...       ...  ...                  ...                ...\n3726       9520      3894  ...                100.0                0.0\n3727      10155      4079  ...                100.0                0.0\n3728       8738      4002  ...                100.0                0.0\n3729       9011      3793  ...                100.0                0.0\n3730       9522      3648  ...                100.0                0.0\n\n[3731 rows x 6 columns]","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
{"timestamp":"2025-06-17T20:00:37.326402","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('01977f7a-259b-793f-8e7c-5f59a7664e2b'), task_id='fact_status_group.transform', dag_id='etl_pipeline', run_id='scheduled__2025-06-17T20:00:00+00:00', try_number=1, map_index=-1, hostname='a0efdb7dc36b', context_carrier={}, task=<Task(PythonOperator): fact_status_group.transform>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=1, start_date=datetime.datetime(2025, 6, 17, 20, 0, 35, 954563, tzinfo=TzInfo(UTC)), end_date=None, is_mapped=False)","logger":"task"}
{"timestamp":"2025-06-17T20:00:37.353502Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-17T20:00:37.354476Z","level":"info","event":" Previous state of the Task instance: running","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-17T20:00:37.354949Z","level":"info","event":"Task operator:<Task(PythonOperator): fact_status_group.transform>","chan":"stdout","logger":"task"}
