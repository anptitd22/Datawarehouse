{"timestamp":"2025-06-14T15:42:24.654636","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-06-14T15:42:24.655208","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-06-14T15:42:24.778417Z","level":"error","event":"%3|1749915744.778|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)","chan":"stderr","logger":"task"}
{"timestamp":"2025-06-14T15:42:24.808917","level":"warning","event":"/opt/airflow/dags/etl_dim_customer.py:18: UserWarning: MessageFactory class is deprecated. Please use GetMessageClass() instead of MessageFactory.GetPrototype. MessageFactory class will be removed after 2024.\n  CustomerMessage = factory.GetPrototype(descriptor)\n","logger":"py.warnings"}
{"timestamp":"2025-06-14T15:42:24.838202Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-14T15:42:24.838750Z","level":"info","event":" Previous state of the Task instance: queued","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-14T15:42:24.839118Z","level":"info","event":"Current task name:fact_status_group.transform","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-14T15:42:24.839501Z","level":"info","event":"Dag name:etl_pipeline","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-14T15:42:24.813411","level":"info","event":"Secrets backends loaded for worker","count":1,"backend_classes":["EnvironmentVariablesBackend"],"logger":"supervisor"}
{"timestamp":"2025-06-14T15:42:24.839207","level":"info","event":"Connection Retrieved 'postgres_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-06-14T15:42:24.851533","level":"warning","event":"/opt/airflow/dags/etl_fact_status.py:24: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  df = pd.read_sql(\"\"\"\n","logger":"py.warnings"}
{"timestamp":"2025-06-14T15:42:24.885868","level":"info","event":"Secrets backends loaded for worker","count":1,"backend_classes":["EnvironmentVariablesBackend"],"logger":"supervisor"}
{"timestamp":"2025-06-14T15:42:24.894528","level":"info","event":"Connection Retrieved 'sqlserver_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-06-14T15:42:24.939554","level":"warning","event":"/opt/airflow/dags/etl_fact_status.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  date_df = pd.read_sql(\"SELECT date, date_key FROM dim_date\", sql_conn)\n","logger":"py.warnings"}
{"timestamp":"2025-06-14T15:42:24.949696","level":"warning","event":"/opt/airflow/dags/etl_fact_status.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  order_df = pd.read_sql(\"SELECT order_id, order_key FROM dim_order\", sql_conn)\n","logger":"py.warnings"}
{"timestamp":"2025-06-14T15:42:24.996660","level":"info","event":"Done. Returned value was:       order_key  date_key  ...  delivery_percentage  cancel_percentage\n0          2259      1185  ...                100.0                0.0\n1          2383       616  ...                100.0                0.0\n2           192       999  ...                100.0                0.0\n3          2056       950  ...                100.0                0.0\n4           619      1036  ...                100.0                0.0\n...         ...       ...  ...                  ...                ...\n3726       2058       972  ...                100.0                0.0\n3727       2693      1157  ...                100.0                0.0\n3728       1276      1080  ...                100.0                0.0\n3729       1549       871  ...                100.0                0.0\n3730       2060       726  ...                100.0                0.0\n\n[3731 rows x 6 columns]","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
{"timestamp":"2025-06-14T15:42:24.996992","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('01976f19-075b-7616-9214-bea54822e6a1'), task_id='fact_status_group.transform', dag_id='etl_pipeline', run_id='scheduled__2025-06-14T15:40:00+00:00', try_number=1, map_index=-1, hostname='0629ca3557f4', context_carrier={}, task=<Task(PythonOperator): fact_status_group.transform>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=1, start_date=datetime.datetime(2025, 6, 14, 15, 42, 24, 13661, tzinfo=TzInfo(UTC)), end_date=None, is_mapped=False)","logger":"task"}
{"timestamp":"2025-06-14T15:42:25.080835Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-14T15:42:25.081326Z","level":"info","event":" Previous state of the Task instance: running","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-14T15:42:25.081671Z","level":"info","event":"Task operator:<Task(PythonOperator): fact_status_group.transform>","chan":"stdout","logger":"task"}
