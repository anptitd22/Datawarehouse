{"timestamp":"2025-06-13T20:40:23.438293","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-06-13T20:40:23.439141","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-06-13T20:40:23.516646Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-13T20:40:23.517625Z","level":"info","event":" Previous state of the Task instance: queued","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-13T20:40:23.518032Z","level":"info","event":"Current task name:fact_status_group.transform","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-13T20:40:23.518305Z","level":"info","event":"Dag name:etl_pipeline","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-13T20:40:23.506905","level":"warning","event":"/opt/airflow/dags/etl_fact_status.py:24: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  df = pd.read_sql(\"\"\"\n","logger":"py.warnings"}
{"timestamp":"2025-06-13T20:40:23.545527","level":"info","event":"Secrets backends loaded for worker","count":1,"backend_classes":["EnvironmentVariablesBackend"],"logger":"supervisor"}
{"timestamp":"2025-06-13T20:40:23.556650","level":"info","event":"Connection Retrieved 'sqlserver_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-06-13T20:40:23.602848","level":"warning","event":"/opt/airflow/dags/etl_fact_status.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  date_df = pd.read_sql(\"SELECT date, date_key FROM dim_date\", sql_conn)\n","logger":"py.warnings"}
{"timestamp":"2025-06-13T20:40:23.609713","level":"warning","event":"/opt/airflow/dags/etl_fact_status.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  order_df = pd.read_sql(\"SELECT order_id, order_key FROM dim_order\", sql_conn)\n","logger":"py.warnings"}
{"timestamp":"2025-06-13T20:40:23.648074","level":"info","event":"Done. Returned value was:       order_key  date_key  ...  delivery_percentage  cancel_percentage\n0          2259      1185  ...                100.0                0.0\n1          2383       616  ...                100.0                0.0\n2           192       999  ...                100.0                0.0\n3          2056       950  ...                100.0                0.0\n4           619      1036  ...                100.0                0.0\n...         ...       ...  ...                  ...                ...\n3726       2058       972  ...                100.0                0.0\n3727       2693      1157  ...                100.0                0.0\n3728       1276      1080  ...                100.0                0.0\n3729       1549       871  ...                100.0                0.0\n3730       2060       726  ...                100.0                0.0\n\n[3731 rows x 6 columns]","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
{"timestamp":"2025-06-13T20:40:23.648390","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('01976b05-53b3-7542-9ec7-23c2ac70f3f6'), task_id='fact_status_group.transform', dag_id='etl_pipeline', run_id='scheduled__2025-06-13T20:40:00+00:00', try_number=1, map_index=-1, hostname='6b02a1a88b4d', context_carrier={}, task=<Task(PythonOperator): fact_status_group.transform>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=1, start_date=datetime.datetime(2025, 6, 13, 20, 40, 22, 816386, tzinfo=TzInfo(UTC)), end_date=None, is_mapped=False)","logger":"task"}
{"timestamp":"2025-06-13T20:40:23.665012Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-13T20:40:23.665518Z","level":"info","event":" Previous state of the Task instance: running","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-13T20:40:23.665893Z","level":"info","event":"Task operator:<Task(PythonOperator): fact_status_group.transform>","chan":"stdout","logger":"task"}
